{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.algosome.com/articles/dummy-variable-trap-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/coinmonks/building-your-own-artificial-neural-network-from-scratch-on-churn-modeling-dataset-using-keras-in-690782f7d051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,sklearn,matplotlib.pyplot as plt,pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Left  \n",
       "0        101348.88     1  \n",
       "1        112542.58     0  \n",
       "2        113931.57     1  \n",
       "3         93826.63     0  \n",
       "4         79084.10     0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,3:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,13] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.get_dummies(X['Geography']).iloc[:,1:]\n",
    "gender = pd.get_dummies(X['Gender']).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaqai\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Male</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Germany  Male  Spain\n",
       "0         0.0   NaN    0.0\n",
       "1         0.0   NaN    1.0\n",
       "2         0.0   NaN    0.0\n",
       "3         0.0   NaN    0.0\n",
       "4         0.0   NaN    1.0\n",
       "5         0.0   NaN    1.0\n",
       "6         0.0   NaN    0.0\n",
       "7         1.0   NaN    0.0\n",
       "8         0.0   NaN    0.0\n",
       "9         0.0   NaN    0.0\n",
       "10        0.0   NaN    0.0\n",
       "11        0.0   NaN    1.0\n",
       "12        0.0   NaN    0.0\n",
       "13        0.0   NaN    0.0\n",
       "14        0.0   NaN    1.0\n",
       "15        1.0   NaN    0.0\n",
       "16        1.0   NaN    0.0\n",
       "17        0.0   NaN    1.0\n",
       "18        0.0   NaN    1.0\n",
       "19        0.0   NaN    0.0\n",
       "20        0.0   NaN    0.0\n",
       "21        0.0   NaN    1.0\n",
       "22        0.0   NaN    1.0\n",
       "23        0.0   NaN    0.0\n",
       "24        0.0   NaN    0.0\n",
       "25        0.0   NaN    0.0\n",
       "26        1.0   NaN    0.0\n",
       "27        0.0   NaN    0.0\n",
       "28        1.0   NaN    0.0\n",
       "29        0.0   NaN    0.0\n",
       "...       ...   ...    ...\n",
       "9970      NaN   1.0    NaN\n",
       "9971      NaN   0.0    NaN\n",
       "9972      NaN   1.0    NaN\n",
       "9973      NaN   1.0    NaN\n",
       "9974      NaN   1.0    NaN\n",
       "9975      NaN   1.0    NaN\n",
       "9976      NaN   0.0    NaN\n",
       "9977      NaN   0.0    NaN\n",
       "9978      NaN   1.0    NaN\n",
       "9979      NaN   0.0    NaN\n",
       "9980      NaN   1.0    NaN\n",
       "9981      NaN   1.0    NaN\n",
       "9982      NaN   0.0    NaN\n",
       "9983      NaN   1.0    NaN\n",
       "9984      NaN   1.0    NaN\n",
       "9985      NaN   1.0    NaN\n",
       "9986      NaN   1.0    NaN\n",
       "9987      NaN   1.0    NaN\n",
       "9988      NaN   1.0    NaN\n",
       "9989      NaN   1.0    NaN\n",
       "9990      NaN   1.0    NaN\n",
       "9991      NaN   0.0    NaN\n",
       "9992      NaN   1.0    NaN\n",
       "9993      NaN   1.0    NaN\n",
       "9994      NaN   0.0    NaN\n",
       "9995      NaN   1.0    NaN\n",
       "9996      NaN   1.0    NaN\n",
       "9997      NaN   0.0    NaN\n",
       "9998      NaN   1.0    NaN\n",
       "9999      NaN   0.0    NaN\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([2,3,4,7],index=[1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series([6,7,89,68],index=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     6\n",
       "2     7\n",
       "3    89\n",
       "4    68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame({\"one\":s1,\"two\":s2,\"two3\":s2,\"tw22o\":s2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>two3</th>\n",
       "      <th>tw22o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one   two  two3  tw22o\n",
       "1  2.0   6.0   6.0    6.0\n",
       "2  3.0   7.0   7.0    7.0\n",
       "3  4.0  89.0  89.0   89.0\n",
       "4  NaN  68.0  68.0   68.0\n",
       "5  7.0   NaN   NaN    NaN"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0               1        101348.88        0      0     0  \n",
       "1               1        112542.58        0      1     0  \n",
       "2               0        113931.57        0      0     0  \n",
       "3               0         93826.63        0      0     0  \n",
       "4               1         79084.10        0      1     0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([geo, gender], axis=1, sort=False)\n",
    "\n",
    "\n",
    "del X[\"Geography\"],X[\"Gender\"]\n",
    "\n",
    "X =  pd.concat([X,result], axis=1, sort=False)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "churn_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "##kernel initializer/init = uniform weights in all synapses\n",
    "\n",
    "churn_model.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Second hidden layer\n",
    "\n",
    "churn_model.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding output layer\n",
    "\n",
    "churn_model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.4812 - acc: 0.8002\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.4211 - acc: 0.8245\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.4131 - acc: 0.8289\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.4080 - acc: 0.8299\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 0.4053 - acc: 0.8331\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4031 - acc: 0.8330\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.4028 - acc: 0.8331\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 0.4019 - acc: 0.8335\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4011 - acc: 0.8350\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4011 - acc: 0.8352 0s - loss: 0.3979 -\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4001 - acc: 0.8362\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3996 - acc: 0.8369\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.4002 - acc: 0.8367\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3995 - acc: 0.8342\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.3987 - acc: 0.8350\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.3986 - acc: 0.8375\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.3984 - acc: 0.8355\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.3986 - acc: 0.8374\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 0.3983 - acc: 0.8357\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3975 - acc: 0.8361\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.3971 - acc: 0.8342\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3971 - acc: 0.8355\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3973 - acc: 0.8347\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3971 - acc: 0.8370\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3971 - acc: 0.8372\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3969 - acc: 0.8371\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3964 - acc: 0.8364\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3960 - acc: 0.8362\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.3958 - acc: 0.8377\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3960 - acc: 0.8374\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 0.3961 - acc: 0.8355\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.3961 - acc: 0.8366\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 0.3955 - acc: 0.8370\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3958 - acc: 0.8356\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3953 - acc: 0.8389\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 0.3954 - acc: 0.8365\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3956 - acc: 0.8382\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3953 - acc: 0.8376\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 0.3950 - acc: 0.8352\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3948 - acc: 0.8367\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3948 - acc: 0.8382\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3952 - acc: 0.8370\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3940 - acc: 0.8359\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.3945 - acc: 0.8360\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.3939 - acc: 0.8367\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.3934 - acc: 0.8365\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3937 - acc: 0.8375 2s - \n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 0.3936 - acc: 0.8382\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.3939 - acc: 0.8382\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 0.3934 - acc: 0.8376\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 0.3931 - acc: 0.8364\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3923 - acc: 0.8370\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3914 - acc: 0.8395\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.3898 - acc: 0.8392\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.3883 - acc: 0.8411\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3858 - acc: 0.8407\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3838 - acc: 0.8395\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.3820 - acc: 0.8421\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.3797 - acc: 0.8380\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 0.3780 - acc: 0.8417\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3774 - acc: 0.8386\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3744 - acc: 0.8394\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.3744 - acc: 0.8424\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3720 - acc: 0.8432\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3709 - acc: 0.8441\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3700 - acc: 0.8426\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.3683 - acc: 0.8409\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 0.3669 - acc: 0.8439\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 0.3662 - acc: 0.8440\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.3648 - acc: 0.8404\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3638 - acc: 0.8405\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.3622 - acc: 0.8416\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3595 - acc: 0.8436\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.3592 - acc: 0.8451\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3582 - acc: 0.8434\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3569 - acc: 0.8456\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3551 - acc: 0.8536\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3543 - acc: 0.8519\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 0.3538 - acc: 0.8520\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 0.3521 - acc: 0.8555\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3525 - acc: 0.8567 0s - loss: 0.3509 - acc: 0.857\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 169us/step - loss: 0.3505 - acc: 0.8582\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3505 - acc: 0.8586\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3492 - acc: 0.8591\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 0.3482 - acc: 0.8596\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3476 - acc: 0.8587\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 176us/step - loss: 0.3463 - acc: 0.8586\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3466 - acc: 0.8610\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3456 - acc: 0.8630\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 178us/step - loss: 0.3452 - acc: 0.8594\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 174us/step - loss: 0.3445 - acc: 0.8605\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 192us/step - loss: 0.3458 - acc: 0.8595\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3433 - acc: 0.8596\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3427 - acc: 0.8624\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.3415 - acc: 0.8620\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3408 - acc: 0.8622\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 166us/step - loss: 0.3410 - acc: 0.8620\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3409 - acc: 0.8641\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 178us/step - loss: 0.3406 - acc: 0.8624\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.3395 - acc: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8a64b4fd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "churn_model.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = churn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = y_pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = y_test.values.reshape(2000,1)\n",
    "compared = y_==test\n",
    "\n",
    "wrong = np.where(compared==False)[0]\n",
    "\n",
    "(len(y_)-len(wrong))/len(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1504,   91],\n",
       "       [ 188,  217]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0,0]+cm[1,1])/len(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = lambda c: cm[0,0]/(cm[0,0]+cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = lambda c:cm[0,0]/(cm[0,0]+cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_val = np.linspace(0,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaqai\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "r,p = [],[]\n",
    "\n",
    "for i in thresh_val:\n",
    "    y_ = y_pred >= i\n",
    "    cm = confusion_matrix(y_test,y_)\n",
    "    \n",
    "    r.append(recall(cm))\n",
    "    p.append(prec(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8a79ddf98>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('threshold')\n",
    "plt.xlabel('p/r')\n",
    "\n",
    "plt.plot(r,thresh_val)\n",
    "plt.plot(p,thresh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = y_pred >= 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pred = y_pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_,y_test):\n",
    "\n",
    "    compared = y_==test\n",
    "\n",
    "    wrong = np.where(compared==False)[0]\n",
    "\n",
    "    return((len(y_)-len(wrong))/len(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(old_pred,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(new_pred,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_keras = churn_model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = churn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_curve in module sklearn.metrics.ranking:\n",
      "\n",
      "roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "    Compute Receiver operating characteristic (ROC)\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    y_true : array, shape = [n_samples]\n",
      "        True binary labels in range {0, 1} or {-1, 1}.  If labels are not\n",
      "        binary, pos_label should be explicitly given.\n",
      "    \n",
      "    y_score : array, shape = [n_samples]\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    pos_label : int or str, default=None\n",
      "        Label considered as positive and others are considered negative.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    drop_intermediate : boolean, optional (default=True)\n",
      "        Whether to drop some suboptimal thresholds which would not appear\n",
      "        on a plotted ROC curve. This is useful in order to create lighter\n",
      "        ROC curves.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           parameter *drop_intermediate*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fpr : array, shape = [>2]\n",
      "        Increasing false positive rates such that element i is the false\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    tpr : array, shape = [>2]\n",
      "        Increasing true positive rates such that element i is the true\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    thresholds : array, shape = [n_thresholds]\n",
      "        Decreasing thresholds on the decision function used to compute\n",
      "        fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "        and is arbitrarily set to `max(y_score) + 1`.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    roc_auc_score : Compute the area under the ROC curve\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Since the thresholds are sorted from low to high values, they\n",
      "    are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "    and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "    >>> fpr\n",
      "    array([ 0. ,  0.5,  0.5,  1. ])\n",
      "    >>> tpr\n",
      "    array([ 0.5,  0.5,  1. ,  1. ])\n",
      "    >>> thresholds\n",
      "    array([ 0.8 ,  0.4 ,  0.35,  0.1 ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
